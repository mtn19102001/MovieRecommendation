{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nBCiXDMzkdto"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EXS44fd5krnI"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"../Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1iojVoORkiUZ"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"FeatureExtracted/dataset.csv\")\n",
        "ratings_train = pd.read_csv(\"CleanedData/ratings_train.csv\")\n",
        "ratings_test = pd.read_csv(\"CleanedData/ratings_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6k5rKc9k720"
      },
      "source": [
        "## Content-Based Recommendation System - Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uP9PPs_wlVQK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lK_ZxPsmHwG"
      },
      "source": [
        "### Make Dataset For Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHRVh4KHnF2N"
      },
      "source": [
        "There are 671 users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwQUxcCZmly4",
        "outputId": "f5dcd945-fa5d-4bf9-d0b2-3b49ce52420c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "671\n"
          ]
        }
      ],
      "source": [
        "len_users = ratings_train['userId'].unique().size\n",
        "print(len_users)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daUnLGdnnNSO"
      },
      "source": [
        "2830 movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn7CGKI8nIXN",
        "outputId": "a3acc688-89cd-40e7-e2d1-4ae453dc798e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2830\n"
          ]
        }
      ],
      "source": [
        "len_dataset = len(dataset)\n",
        "print(len_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05nl88knoDCp"
      },
      "source": [
        "We need to save the id for later recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "Et32VfWBnwF8",
        "outputId": "6d9dca02-2f3c-47d4-9916-f017b0119e74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>budget</th>\n",
              "      <th>id</th>\n",
              "      <th>runtime</th>\n",
              "      <th>revenue</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>CastsRank</th>\n",
              "      <th>NumLeadActors</th>\n",
              "      <th>HasTop50Actors</th>\n",
              "      <th>NumCrews</th>\n",
              "      <th>...</th>\n",
              "      <th>History</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Music</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Science Fiction</th>\n",
              "      <th>TV Movie</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000000</td>\n",
              "      <td>949</td>\n",
              "      <td>170.0</td>\n",
              "      <td>187436818.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>13852</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58000000</td>\n",
              "      <td>710</td>\n",
              "      <td>130.0</td>\n",
              "      <td>352194034.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>5916</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98000000</td>\n",
              "      <td>1408</td>\n",
              "      <td>119.0</td>\n",
              "      <td>10017322.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3481</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52000000</td>\n",
              "      <td>524</td>\n",
              "      <td>178.0</td>\n",
              "      <td>116112375.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1343.0</td>\n",
              "      <td>6894</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16500000</td>\n",
              "      <td>4584</td>\n",
              "      <td>136.0</td>\n",
              "      <td>135000000.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>364.0</td>\n",
              "      <td>4392</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2825</th>\n",
              "      <td>0</td>\n",
              "      <td>80831</td>\n",
              "      <td>121.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1374</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2826</th>\n",
              "      <td>0</td>\n",
              "      <td>3104</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1054</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2827</th>\n",
              "      <td>0</td>\n",
              "      <td>64197</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>729</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2828</th>\n",
              "      <td>0</td>\n",
              "      <td>98604</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2385</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2829</th>\n",
              "      <td>0</td>\n",
              "      <td>49280</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>22.0</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2830 rows × 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        budget     id  runtime      revenue  vote_average  vote_count  \\\n",
              "0     60000000    949    170.0  187436818.0           7.7      1886.0   \n",
              "1     58000000    710    130.0  352194034.0           6.6      1194.0   \n",
              "2     98000000   1408    119.0   10017322.0           5.7       137.0   \n",
              "3     52000000    524    178.0  116112375.0           7.8      1343.0   \n",
              "4     16500000   4584    136.0  135000000.0           7.2       364.0   \n",
              "...        ...    ...      ...          ...           ...         ...   \n",
              "2825         0  80831    121.0          0.0           6.5         2.0   \n",
              "2826         0   3104     92.0          0.0           5.9        33.0   \n",
              "2827         0  64197     97.0          0.0           6.0         5.0   \n",
              "2828         0  98604     91.0          0.0           4.6         6.0   \n",
              "2829         0  49280      1.0          0.0           6.5        22.0   \n",
              "\n",
              "      CastsRank  NumLeadActors  HasTop50Actors  NumCrews  ...  History  \\\n",
              "0         13852              3               0        71  ...        0   \n",
              "1          5916              3               1        46  ...        0   \n",
              "2          3481              0               0        16  ...        0   \n",
              "3          6894              0               0        10  ...        0   \n",
              "4          4392              2               1         8  ...        0   \n",
              "...         ...            ...             ...       ...  ...      ...   \n",
              "2825       1374              0               0         4  ...        0   \n",
              "2826       1054              0               0        11  ...        0   \n",
              "2827        729              0               0         4  ...        0   \n",
              "2828       2385              0               0         4  ...        0   \n",
              "2829        123              0               0         1  ...        0   \n",
              "\n",
              "      Horror  Music  Mystery  Romance  Science Fiction  TV Movie  Thriller  \\\n",
              "0          0      0        0        0                0         0         1   \n",
              "1          0      0        0        0                0         0         1   \n",
              "2          0      0        0        0                0         0         0   \n",
              "3          0      0        0        0                0         0         0   \n",
              "4          0      0        0        1                0         0         0   \n",
              "...      ...    ...      ...      ...              ...       ...       ...   \n",
              "2825       0      0        0        0                0         0         0   \n",
              "2826       1      0        0        0                1         0         0   \n",
              "2827       0      0        0        1                0         0         0   \n",
              "2828       0      0        0        1                0         0         0   \n",
              "2829       0      0        0        0                0         0         1   \n",
              "\n",
              "      War  Western  \n",
              "0       0        0  \n",
              "1       0        0  \n",
              "2       0        0  \n",
              "3       0        0  \n",
              "4       0        0  \n",
              "...   ...      ...  \n",
              "2825    0        0  \n",
              "2826    0        0  \n",
              "2827    0        0  \n",
              "2828    0        0  \n",
              "2829    0        0  \n",
              "\n",
              "[2830 rows x 39 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bs0TVnKboIt7"
      },
      "outputs": [],
      "source": [
        "indexToId = dict(zip(dataset.index, dataset['id']))\n",
        "idToIndex = dict(zip(dataset['id'], dataset.index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHTw-2JnoUkD",
        "outputId": "33f274ce-6a72-46e1-b803-f18c6fc12d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "949"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexToId[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0haQ_ZQfocEf"
      },
      "outputs": [],
      "source": [
        "dataset.drop(columns = ['id'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t8nVePeV9ZD"
      },
      "source": [
        "Standardlize the dataset by each column to mean of 0 and standard deviation of 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RPDj7O4HJKz5"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZtLdMonHKIrh"
      },
      "outputs": [],
      "source": [
        "dataset = preprocessing.scale(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f9WxSPJT_m2z"
      },
      "outputs": [],
      "source": [
        "len_features = dataset.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOrXg1Ep1zR"
      },
      "source": [
        "Test Transfrom Metadata Movies Dataframe to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lCdA5Bq2pSYm"
      },
      "outputs": [],
      "source": [
        "movies_tensor = torch.tensor(dataset, requires_grad= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgy1cJVkp4mH"
      },
      "source": [
        "Test Transform Ratings to Sparse Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zfVG0vXlqeUg"
      },
      "outputs": [],
      "source": [
        "ratings_train[\"movieId\"] = ratings_train[\"movieId\"].apply(lambda x: idToIndex[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P0GDITByrarE"
      },
      "outputs": [],
      "source": [
        "ratings_test[\"movieId\"] = ratings_test[\"movieId\"].apply(lambda x: idToIndex[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK9aLxXEqZTJ",
        "outputId": "b9545a40-f5ed-4c18-83b0-0252a9bf379d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ratings_train['userId'].unique()) == len(ratings_test['userId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1FpqymVAsGIX"
      },
      "outputs": [],
      "source": [
        "ratings_train[\"userId\"] = ratings_train[\"userId\"].apply(lambda x: x - 1)\n",
        "ratings_test[\"userId\"] = ratings_test[\"userId\"].apply(lambda x: x - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wBXdwLd1sZW9",
        "outputId": "7d1fa829-b40b-437f-f7e2-086440c6f12f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>474</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>618</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>835</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1614</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1618</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31185</th>\n",
              "      <td>670</td>\n",
              "      <td>1454</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31186</th>\n",
              "      <td>670</td>\n",
              "      <td>769</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31187</th>\n",
              "      <td>670</td>\n",
              "      <td>337</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31188</th>\n",
              "      <td>670</td>\n",
              "      <td>1235</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31189</th>\n",
              "      <td>670</td>\n",
              "      <td>2323</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31190 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating\n",
              "0           0      474     2.5\n",
              "1           0      618     2.0\n",
              "2           0      835     2.0\n",
              "3           0     1614     2.5\n",
              "4           1     1618     5.0\n",
              "...       ...      ...     ...\n",
              "31185     670     1454     5.0\n",
              "31186     670      769     4.5\n",
              "31187     670      337     4.0\n",
              "31188     670     1235     3.5\n",
              "31189     670     2323     4.0\n",
              "\n",
              "[31190 rows x 3 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1Cqd1dV5p1D0"
      },
      "outputs": [],
      "source": [
        "ratings_tensor = torch.sparse_coo_tensor([ratings_train['userId'], ratings_train['movieId']], ratings_train['rating'], (len_users, len_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nemaEJj7tDai",
        "outputId": "42da52e9-04bc-4831-b48a-ba209d10b807"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.5000, dtype=torch.float64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_tensor[0][474]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaFwcoPGtQ9s"
      },
      "source": [
        "All works normally!\n",
        "\n",
        "Now we will put all those codes into one block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dPoOLXdiuEaI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This codes convert dataset to Tensor data structure\n",
        "\"\"\"\n",
        "\n",
        "movies_tensor = torch.tensor(dataset, requires_grad= False)\n",
        "movies_tensor = torch.cat((movies_tensor, torch.ones(len_dataset, 1, dtype = torch.float64)), axis = 1)\n",
        "ratings_train_tensor = torch.sparse_coo_tensor([ratings_train['userId'],\\\n",
        "                                                     ratings_train['movieId']],\\\n",
        "                                                     ratings_train['rating'], (len_users, len_dataset))\n",
        "ratings_test_tensor = torch.sparse_coo_tensor([ratings_test['userId'],\\\n",
        "                                                     ratings_test['movieId']],\\\n",
        "                                                     ratings_test['rating'], (len_users, len_dataset))\n",
        "\n",
        "ratings_train_tensor = ratings_train_tensor.to_dense()\n",
        "ratings_test_tensor = ratings_test_tensor.to_dense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "l4xf3ae7ur7s"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQkPDoq4xlIt",
        "outputId": "ddfaaee0-fca5-4df7-f355-ce2f9be58f5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.5000, dtype=torch.float64)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_train_tensor[0][474]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L0c6SXJv9WX"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X53qYJbAfBa"
      },
      "source": [
        "We proposed a Regression Model for predicting Ratings\n",
        "\n",
        "To predict the rate from user model $U$ and movies profiles $M$:\n",
        "\n",
        "$U$ * $M^\\top$ = $\\hat{R}$ \n",
        "\n",
        "$L = MSE(\\hat{R}, R)$ for all movies that have rated \n",
        "\n",
        "Find the partial derivatives for matrix $U$ : $ \\dfrac{\\partial L}{\\partial U} $\n",
        "\n",
        "Update $U$ based on $ \\dfrac{\\partial L}{\\partial U} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Hk-5ctEfa2"
      },
      "source": [
        "To calculate derivatives, we use **Autograd** of ***Pytorch***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "esuVsSYYL8C-",
        "outputId": "0717f23f-a3ae-4be9-f8da-bc2c8c8c728a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAutograd example\\n'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Autograd example\n",
        "\"\"\"\n",
        "# ratings_pred = torch.matmul(torch.cat((U, b), axis = 1), movies_tensor.T)\n",
        "# mask = ratings_train_tensor.bool()\n",
        "# nonzero_pred = ratings_pred.masked_select(mask)\n",
        "# nonzero_train = ratings_train_tensor.masked_select(mask)\n",
        "# loss = criterion(nonzero_pred, nonzero_train)\n",
        "# loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2rkcb4C3ouo3"
      },
      "outputs": [],
      "source": [
        "U = Variable(torch.randn(len_users, len_features, dtype = torch.float64), requires_grad=True)\n",
        "b = Variable(torch.randn(len_users, 1, dtype = torch.float64), requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUHgQL2eD95N"
      },
      "source": [
        "Here we use MSELoss (**Mean Square Error**)\n",
        "\n",
        "We also use this loss as metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "m3oji6TMIC6g"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam([U], lr = 0.005)\n",
        "optimizer.add_param_group({'params': b, \"lr\": 0.005, \"weight_decay\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xJ_-m9TmLk0x"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GMgm2bhOU4OM"
      },
      "outputs": [],
      "source": [
        "bestU = None\n",
        "bestb = None\n",
        "minLoss = 10e10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUx-KhHQVkda"
      },
      "source": [
        "First try 3001 loop without regulization, lr = 0.005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "40e878e6253c4f4b8df8dcf9a6154270",
            "e599ed8b209145819b374acc5632453e",
            "10bf11ffa98b4e3db983996a1c2312f5",
            "2754049777b64696a792343cddb4183f",
            "e20c010704724632ae65fce3bee1227e",
            "a87f5641a4cc45e4b9680c4f39f10adb",
            "f7e37addf6634720951ecad54ff229b5",
            "7e09e24747c64b2ba9365f0a9a5824ea",
            "3dda87b7df3849b59c4dbbcf69be4435",
            "3c4a934113a04c1a90263772a5f344a5",
            "c290ae7d67cc4edcb909f16b6936107f"
          ]
        },
        "id": "Z6zLIEjrIG9l",
        "outputId": "a7a2e0d8-f891-4048-92d4-77ba4c0f9840"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac1d3b84734344d1b7907811f6755084",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3001 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0. Train Loss: 64.10655643566844. Valid Loss: 62.37670454644261.\n",
            "Epoch: 10. Train Loss: 56.6606566141118. Valid Loss: 56.805391539242244.\n",
            "Epoch: 20. Train Loss: 50.25430154906511. Valid Loss: 52.08661616749644.\n",
            "Epoch: 30. Train Loss: 44.79605361231597. Valid Loss: 48.12330855560293.\n",
            "Epoch: 40. Train Loss: 40.15082464491162. Valid Loss: 44.78968902764665.\n",
            "Epoch: 50. Train Loss: 36.185571582150814. Valid Loss: 41.96866450447321.\n",
            "Epoch: 60. Train Loss: 32.78295980867981. Valid Loss: 39.56406021635322.\n",
            "Epoch: 70. Train Loss: 29.84458041398937. Valid Loss: 37.49865484352405.\n",
            "Epoch: 80. Train Loss: 27.290214368687977. Valid Loss: 35.71052548383428.\n",
            "Epoch: 90. Train Loss: 25.055245258972278. Valid Loss: 34.15060221266894.\n",
            "Epoch: 100. Train Loss: 23.08767293314678. Valid Loss: 32.78067766909476.\n",
            "Epoch: 110. Train Loss: 21.34553162542222. Valid Loss: 31.56991662270118.\n",
            "Epoch: 120. Train Loss: 19.794780221858847. Valid Loss: 30.493296436739023.\n",
            "Epoch: 130. Train Loss: 18.407622592229416. Valid Loss: 29.53044196020637.\n",
            "Epoch: 140. Train Loss: 17.161212672221236. Valid Loss: 28.66473944758214.\n",
            "Epoch: 150. Train Loss: 16.036649407722837. Valid Loss: 27.882529612724166.\n",
            "Epoch: 160. Train Loss: 15.018191524880514. Valid Loss: 27.172568041343833.\n",
            "Epoch: 170. Train Loss: 14.092641526700186. Valid Loss: 26.525523278730173.\n",
            "Epoch: 180. Train Loss: 13.24886080815317. Valid Loss: 25.93356948876483.\n",
            "Epoch: 190. Train Loss: 12.477387018367278. Valid Loss: 25.390124233508534.\n",
            "Epoch: 200. Train Loss: 11.770131163854437. Valid Loss: 24.889633867896475.\n",
            "Epoch: 210. Train Loss: 11.120136951054615. Valid Loss: 24.42737536735006.\n",
            "Epoch: 220. Train Loss: 10.521388656974892. Valid Loss: 23.999298492774443.\n",
            "Epoch: 230. Train Loss: 9.968656840924629. Valid Loss: 23.601907436725913.\n",
            "Epoch: 240. Train Loss: 9.457373648459674. Valid Loss: 23.23216711090525.\n",
            "Epoch: 250. Train Loss: 8.983531359211216. Valid Loss: 22.88742797168666.\n",
            "Epoch: 260. Train Loss: 8.543599293274022. Valid Loss: 22.56536521594232.\n",
            "Epoch: 270. Train Loss: 8.134455304464614. Valid Loss: 22.26392916381681.\n",
            "Epoch: 280. Train Loss: 7.753328935238295. Valid Loss: 21.98130473463376.\n",
            "Epoch: 290. Train Loss: 7.397753952776757. Valid Loss: 21.71587829819136.\n",
            "Epoch: 300. Train Loss: 7.065528478706777. Valid Loss: 21.466210286815233.\n",
            "Epoch: 310. Train Loss: 6.754681303534763. Valid Loss: 21.231012239758982.\n",
            "Epoch: 320. Train Loss: 6.463443269194527. Valid Loss: 21.00912753156388.\n",
            "Epoch: 330. Train Loss: 6.190222830032945. Valid Loss: 20.79951510626567.\n",
            "Epoch: 340. Train Loss: 5.933585079545475. Valid Loss: 20.60123567970304.\n",
            "Epoch: 350. Train Loss: 5.692233668786094. Valid Loss: 20.413439923605203.\n",
            "Epoch: 360. Train Loss: 5.464995151405322. Valid Loss: 20.235358326141075.\n",
            "Epoch: 370. Train Loss: 5.25080537640785. Valid Loss: 20.066292440675504.\n",
            "Epoch: 380. Train Loss: 5.0486976180751615. Valid Loss: 19.905607269099495.\n",
            "Epoch: 390. Train Loss: 4.857792186992691. Valid Loss: 19.75272460299692.\n",
            "Epoch: 400. Train Loss: 4.677287309784011. Valid Loss: 19.607117177861852.\n",
            "Epoch: 410. Train Loss: 4.50645110032705. Valid Loss: 19.468303518761324.\n",
            "Epoch: 420. Train Loss: 4.344614473723625. Valid Loss: 19.335843378313943.\n",
            "Epoch: 430. Train Loss: 4.191164877520508. Valid Loss: 19.20933368547642.\n",
            "Epoch: 440. Train Loss: 4.0455407337313805. Valid Loss: 19.088404938023956.\n",
            "Epoch: 450. Train Loss: 3.907226500933852. Valid Loss: 18.972717982643005.\n",
            "Epoch: 460. Train Loss: 3.775748278777127. Valid Loss: 18.86196113473652.\n",
            "Epoch: 470. Train Loss: 3.6506698881509854. Valid Loss: 18.755847597301546.\n",
            "Epoch: 480. Train Loss: 3.5315893694411957. Valid Loss: 18.654113143833616.\n",
            "Epoch: 490. Train Loss: 3.4181358490494214. Valid Loss: 18.556514035122287.\n",
            "Epoch: 500. Train Loss: 3.309966730939784. Valid Loss: 18.46282514381984.\n",
            "Epoch: 510. Train Loss: 3.206765175590579. Valid Loss: 18.372838264022306.\n",
            "Epoch: 520. Train Loss: 3.1082378335394893. Valid Loss: 18.286360585994593.\n",
            "Epoch: 530. Train Loss: 3.014112804844207. Valid Loss: 18.203213318626368.\n",
            "Epoch: 540. Train Loss: 2.9241377993435984. Valid Loss: 18.123230444308067.\n",
            "Epoch: 550. Train Loss: 2.8380784756843433. Valid Loss: 18.046257592728583.\n",
            "Epoch: 560. Train Loss: 2.755716939746212. Valid Loss: 17.97215102165708.\n",
            "Epoch: 570. Train Loss: 2.676850385415464. Valid Loss: 17.900776694116306.\n",
            "Epoch: 580. Train Loss: 2.6012898626705256. Valid Loss: 17.832009442523454.\n",
            "Epoch: 590. Train Loss: 2.5288591596992296. Valid Loss: 17.76573221138648.\n",
            "Epoch: 600. Train Loss: 2.459393787298463. Valid Loss: 17.701835371024476.\n",
            "Epoch: 610. Train Loss: 2.3927400551454117. Valid Loss: 17.640216095550045.\n",
            "Epoch: 620. Train Loss: 2.328754230700964. Valid Loss: 17.580777799026702.\n",
            "Epoch: 630. Train Loss: 2.2673017725325115. Valid Loss: 17.52342962430836.\n",
            "Epoch: 640. Train Loss: 2.208256630744609. Valid Loss: 17.46808597959409.\n",
            "Epoch: 650. Train Loss: 2.1515006079983445. Valid Loss: 17.414666118199072.\n",
            "Epoch: 660. Train Loss: 2.09692277529796. Valid Loss: 17.363093757460938.\n",
            "Epoch: 670. Train Loss: 2.0444189373387025. Valid Loss: 17.313296733076253.\n",
            "Epoch: 680. Train Loss: 1.9938911427535826. Valid Loss: 17.265206685500623.\n",
            "Epoch: 690. Train Loss: 1.9452472350778813. Valid Loss: 17.21875877535287.\n",
            "Epoch: 700. Train Loss: 1.898400440676809. Valid Loss: 17.173891425042314.\n",
            "Epoch: 710. Train Loss: 1.8532689902604726. Valid Loss: 17.13054608409219.\n",
            "Epoch: 720. Train Loss: 1.8097757709472264. Valid Loss: 17.08866701586409.\n",
            "Epoch: 730. Train Loss: 1.7678480061366015. Valid Loss: 17.048201103600057.\n",
            "Epoch: 740. Train Loss: 1.7274169607208627. Valid Loss: 17.00909767389307.\n",
            "Epoch: 750. Train Loss: 1.6884176694035646. Valid Loss: 16.971308335873804.\n",
            "Epoch: 760. Train Loss: 1.6507886861076833. Valid Loss: 16.93478683456418.\n",
            "Epoch: 770. Train Loss: 1.614471852647844. Valid Loss: 16.899488916996592.\n",
            "Epoch: 780. Train Loss: 1.579412085013409. Valid Loss: 16.86537220983358.\n",
            "Epoch: 790. Train Loss: 1.5455571757638966. Valid Loss: 16.832396107346412.\n",
            "Epoch: 800. Train Loss: 1.512857611177353. Valid Loss: 16.8005216687244.\n",
            "Epoch: 810. Train Loss: 1.4812664019175537. Valid Loss: 16.769711523789272.\n",
            "Epoch: 820. Train Loss: 1.450738926098771. Valid Loss: 16.73992978628275.\n",
            "Epoch: 830. Train Loss: 1.4212327837286394. Valid Loss: 16.711141973980173.\n",
            "Epoch: 840. Train Loss: 1.3927076616014948. Valid Loss: 16.683314934959917.\n",
            "Epoch: 850. Train Loss: 1.365125207797569. Valid Loss: 16.656416779428064.\n",
            "Epoch: 860. Train Loss: 1.3384489150183843. Valid Loss: 16.630416816560253.\n",
            "Epoch: 870. Train Loss: 1.312644012056562. Valid Loss: 16.605285495879464.\n",
            "Epoch: 880. Train Loss: 1.2876773627596263. Valid Loss: 16.580994352739246.\n",
            "Epoch: 890. Train Loss: 1.2635173719029977. Valid Loss: 16.557515957527603.\n",
            "Epoch: 900. Train Loss: 1.2401338974377494. Valid Loss: 16.534823868247763.\n",
            "Epoch: 910. Train Loss: 1.217498168624384. Valid Loss: 16.512892586168665.\n",
            "Epoch: 920. Train Loss: 1.1955827096053373. Valid Loss: 16.491697514270808.\n",
            "Epoch: 930. Train Loss: 1.1743612680065432. Valid Loss: 16.471214918242296.\n",
            "Epoch: 940. Train Loss: 1.1538087481925803. Valid Loss: 16.451421889806056.\n",
            "Epoch: 950. Train Loss: 1.1339011488309885. Valid Loss: 16.43229631218229.\n",
            "Epoch: 960. Train Loss: 1.1146155044496138. Valid Loss: 16.41381682751092.\n",
            "Epoch: 970. Train Loss: 1.0959298306965644. Valid Loss: 16.395962806077033.\n",
            "Epoch: 980. Train Loss: 1.077823073035794. Valid Loss: 16.378714317198607.\n",
            "Epoch: 990. Train Loss: 1.0602750586326943. Valid Loss: 16.362052101650196.\n",
            "Epoch: 1000. Train Loss: 1.0432664512035525. Valid Loss: 16.34595754550891.\n",
            "Epoch: 1010. Train Loss: 1.0267787086205398. Valid Loss: 16.33041265532044.\n",
            "Epoch: 1020. Train Loss: 1.010794043080118. Valid Loss: 16.315400034492864.\n",
            "Epoch: 1030. Train Loss: 0.9952953836576386. Valid Loss: 16.30090286083456.\n",
            "Epoch: 1040. Train Loss: 0.9802663410844804. Valid Loss: 16.286904865160828.\n",
            "Epoch: 1050. Train Loss: 0.9656911745965406. Valid Loss: 16.273390310900286.\n",
            "Epoch: 1060. Train Loss: 0.9515547607142896. Valid Loss: 16.26034397463851.\n",
            "Epoch: 1070. Train Loss: 0.9378425638250723. Valid Loss: 16.24775112754184.\n",
            "Epoch: 1080. Train Loss: 0.9245406084479475. Valid Loss: 16.235597517608845.\n",
            "Epoch: 1090. Train Loss: 0.9116354530701721. Valid Loss: 16.223869352701588.\n",
            "Epoch: 1100. Train Loss: 0.8991141654525595. Valid Loss: 16.21255328431231.\n",
            "Epoch: 1110. Train Loss: 0.8869642993084015. Valid Loss: 16.201636392024824.\n",
            "Epoch: 1120. Train Loss: 0.875173872267513. Valid Loss: 16.19110616863271.\n",
            "Epoch: 1130. Train Loss: 0.863731345043299. Valid Loss: 16.180950505879434.\n",
            "Epoch: 1140. Train Loss: 0.8526256017265726. Valid Loss: 16.171157680787573.\n",
            "Epoch: 1150. Train Loss: 0.8418459311352472. Valid Loss: 16.16171634254691.\n",
            "Epoch: 1160. Train Loss: 0.8313820091539936. Valid Loss: 16.152615499932907.\n",
            "Epoch: 1170. Train Loss: 0.8212238820025545. Valid Loss: 16.143844509229027.\n",
            "Epoch: 1180. Train Loss: 0.811361950375647. Valid Loss: 16.135393062627873.\n",
            "Epoch: 1190. Train Loss: 0.8017869544013217. Valid Loss: 16.127251177087828.\n",
            "Epoch: 1200. Train Loss: 0.7924899593682734. Valid Loss: 16.119409183623027.\n",
            "Epoch: 1210. Train Loss: 0.7834623421759709. Valid Loss: 16.11185771700593.\n",
            "Epoch: 1220. Train Loss: 0.7746957784645869. Valid Loss: 16.10458770586296.\n",
            "Epoch: 1230. Train Loss: 0.7661822303846024. Valid Loss: 16.097590363144548.\n",
            "Epoch: 1240. Train Loss: 0.7579139349686325. Valid Loss: 16.09085717695217.\n",
            "Epoch: 1250. Train Loss: 0.7498833930705142. Valid Loss: 16.084379901705866.\n",
            "Epoch: 1260. Train Loss: 0.7420833588389976. Valid Loss: 16.07815054963646.\n",
            "Epoch: 1270. Train Loss: 0.7345068296955167. Valid Loss: 16.072161382587726.\n",
            "Epoch: 1280. Train Loss: 0.7271470367875188. Valid Loss: 16.066404904114385.\n",
            "Epoch: 1290. Train Loss: 0.7199974358906635. Valid Loss: 16.060873851862688.\n",
            "Epoch: 1300. Train Loss: 0.7130516987349225. Valid Loss: 16.05556119022082.\n",
            "Epoch: 1310. Train Loss: 0.7063037047312108. Valid Loss: 16.05046010322733.\n",
            "Epoch: 1320. Train Loss: 0.6997475330766565. Valid Loss: 16.04556398772606.\n",
            "Epoch: 1330. Train Loss: 0.6933774552179978. Valid Loss: 16.040866446756922.\n",
            "Epoch: 1340. Train Loss: 0.6871879276538828. Valid Loss: 16.0363612831723.\n",
            "Epoch: 1350. Train Loss: 0.6811735850580347. Valid Loss: 16.032042493469334.\n",
            "Epoch: 1360. Train Loss: 0.6753292337063656. Valid Loss: 16.027904261828986.\n",
            "Epoch: 1370. Train Loss: 0.6696498451921483. Valid Loss: 16.02394095435316.\n",
            "Epoch: 1380. Train Loss: 0.6641305504143321. Valid Loss: 16.02014711349163.\n",
            "Epoch: 1390. Train Loss: 0.6587666338249728. Valid Loss: 16.016517452650927.\n",
            "Epoch: 1400. Train Loss: 0.6535535279226005. Valid Loss: 16.01304685097787.\n",
            "Epoch: 1410. Train Loss: 0.648486807979119. Valid Loss: 16.009730348310548.\n",
            "Epoch: 1420. Train Loss: 0.643562186988564. Valid Loss: 16.00656314029032.\n",
            "Epoch: 1430. Train Loss: 0.6387755108267311. Valid Loss: 16.00354057362829.\n",
            "Epoch: 1440. Train Loss: 0.6341227536113098. Valid Loss: 16.000658141520432.\n",
            "Epoch: 1450. Train Loss: 0.6296000132527682. Valid Loss: 15.997911479205625.\n",
            "Epoch: 1460. Train Loss: 0.6252035071867694. Valid Loss: 15.99529635966122.\n",
            "Epoch: 1470. Train Loss: 0.6209295682794364. Valid Loss: 15.992808689431076.\n",
            "Epoch: 1480. Train Loss: 0.616774640897254. Valid Loss: 15.990444504581124.\n",
            "Epoch: 1490. Train Loss: 0.6127352771338535. Valid Loss: 15.988199966778017.\n",
            "Epoch: 1500. Train Loss: 0.6088081331863566. Valid Loss: 15.986071359486328.\n",
            "Epoch: 1510. Train Loss: 0.6049899658743413. Valid Loss: 15.98405508428029.\n",
            "Epoch: 1520. Train Loss: 0.6012776292948736. Valid Loss: 15.98214765726608.\n",
            "Epoch: 1530. Train Loss: 0.5976680716073961. Valid Loss: 15.980345705610878.\n",
            "Epoch: 1540. Train Loss: 0.5941583319425879. Valid Loss: 15.978645964175202.\n",
            "Epoch: 1550. Train Loss: 0.5907455374296259. Valid Loss: 15.977045272245055.\n",
            "Epoch: 1560. Train Loss: 0.5874269003365565. Valid Loss: 15.975540570360707.\n",
            "Epoch: 1570. Train Loss: 0.5841997153187679. Valid Loss: 15.974128897239005.\n",
            "Epoch: 1580. Train Loss: 0.581061356770799. Valid Loss: 15.972807386786242.\n",
            "Epoch: 1590. Train Loss: 0.5780092762769684. Valid Loss: 15.971573265198833.\n",
            "Epoch: 1600. Train Loss: 0.5750410001565286. Valid Loss: 15.970423848149052.\n",
            "Epoch: 1610. Train Loss: 0.5721541270992645. Valid Loss: 15.969356538053274.\n",
            "Epoch: 1620. Train Loss: 0.5693463258876554. Valid Loss: 15.968368821420302.\n",
            "Epoch: 1630. Train Loss: 0.5666153332019095. Valid Loss: 15.96745826627731.\n",
            "Epoch: 1640. Train Loss: 0.5639589515043587. Valid Loss: 15.966622519671253.\n",
            "Epoch: 1650. Train Loss: 0.5613750469998681. Valid Loss: 15.965859305243457.\n",
            "Epoch: 1660. Train Loss: 0.5588615476690749. Valid Loss: 15.965166420875363.\n",
            "Epoch: 1670. Train Loss: 0.5564164413714237. Valid Loss: 15.964541736403365.\n",
            "Epoch: 1680. Train Loss: 0.5540377740151026. Valid Loss: 15.963983191400791.\n",
            "Epoch: 1690. Train Loss: 0.5517236477911257. Valid Loss: 15.963488793025153.\n",
            "Epoch: 1700. Train Loss: 0.5494722194689307. Valid Loss: 15.963056613928844.\n",
            "Epoch: 1710. Train Loss: 0.5472816987509799. Valid Loss: 15.962684790231526.\n",
            "Epoch: 1720. Train Loss: 0.5451503466839742. Valid Loss: 15.962371519552496.\n",
            "Epoch: 1730. Train Loss: 0.5430764741243912. Valid Loss: 15.962115059101372.\n",
            "Epoch: 1740. Train Loss: 0.5410584402561659. Valid Loss: 15.961913723825514.\n",
            "Epoch: 1750. Train Loss: 0.5390946511584288. Valid Loss: 15.961765884612621.\n",
            "Epoch: 1760. Train Loss: 0.5371835584213103. Valid Loss: 15.961669966546955.\n",
            "Epoch: 1770. Train Loss: 0.5353236578079081. Valid Loss: 15.96162444721781.\n",
            "Epoch: 1780. Train Loss: 0.5335134879605998. Valid Loss: 15.961627855078676.\n",
            "Epoch: 1790. Train Loss: 0.5317516291499598. Valid Loss: 15.961678767855805.\n",
            "Epoch: 1800. Train Loss: 0.5300367020646202. Valid Loss: 15.961775811004765.\n",
            "Epoch: 1810. Train Loss: 0.5283673666404856. Valid Loss: 15.961917656213702.\n",
            "Epoch: 1820. Train Loss: 0.5267423209277805. Valid Loss: 15.96210301995197.\n",
            "Epoch: 1830. Train Loss: 0.5251602999944749. Valid Loss: 15.962330662062909.\n",
            "Epoch: 1840. Train Loss: 0.523620074864697. Valid Loss: 15.962599384399539.\n",
            "Epoch: 1850. Train Loss: 0.5221204514908009. Valid Loss: 15.962908029501943.\n",
            "Epoch: 1860. Train Loss: 0.520660269757815. Valid Loss: 15.9632554793152.\n",
            "Epoch: 1870. Train Loss: 0.5192384025190512. Valid Loss: 15.963640653946692.\n",
            "Epoch: 1880. Train Loss: 0.5178537546617072. Valid Loss: 15.96406251046173.\n",
            "Epoch: 1890. Train Loss: 0.5165052622013449. Valid Loss: 15.964520041716316.\n",
            "Epoch: 1900. Train Loss: 0.515191891404173. Valid Loss: 15.965012275226027.\n",
            "Epoch: 1910. Train Loss: 0.5139126379361114. Valid Loss: 15.965538272070006.\n",
            "Epoch: 1920. Train Loss: 0.5126665260376543. Valid Loss: 15.966097125828977.\n",
            "Epoch: 1930. Train Loss: 0.5114526077235921. Valid Loss: 15.966687961556326.\n",
            "Epoch: 1940. Train Loss: 0.5102699620066947. Valid Loss: 15.96730993478127.\n",
            "Epoch: 1950. Train Loss: 0.50911769414449. Valid Loss: 15.967962230543161.\n",
            "Epoch: 1960. Train Loss: 0.5079949349083166. Valid Loss: 15.968644062456004.\n",
            "Epoch: 1970. Train Loss: 0.5069008398738548. Valid Loss: 15.969354671802272.\n",
            "Epoch: 1980. Train Loss: 0.5058345887323829. Valid Loss: 15.97009332665512.\n",
            "Epoch: 1990. Train Loss: 0.5047953846220279. Valid Loss: 15.970859321028188.\n",
            "Epoch: 2000. Train Loss: 0.5037824534783204. Valid Loss: 15.971651974052081.\n",
            "Epoch: 2010. Train Loss: 0.5027950434033813. Valid Loss: 15.97247062917675.\n",
            "Epoch: 2020. Train Loss: 0.5018324240531066. Valid Loss: 15.973314653398932.\n",
            "Epoch: 2030. Train Loss: 0.5008938860417347. Valid Loss: 15.974183436513929.\n",
            "Epoch: 2040. Train Loss: 0.4999787403632115. Valid Loss: 15.975076390390887.\n",
            "Epoch: 2050. Train Loss: 0.4990863178287902. Valid Loss: 15.97599294827089.\n",
            "Epoch: 2060. Train Loss: 0.4982159685203261. Valid Loss: 15.97693256408708.\n",
            "Epoch: 2070. Train Loss: 0.4973670612587507. Valid Loss: 15.97789471180622.\n",
            "Epoch: 2080. Train Loss: 0.4965389830872296. Valid Loss: 15.978878884790818.\n",
            "Epoch: 2090. Train Loss: 0.4957311387685275. Valid Loss: 15.979884595181403.\n",
            "Epoch: 2100. Train Loss: 0.4949429502961262. Valid Loss: 15.980911373298714.\n",
            "Epoch: 2110. Train Loss: 0.49417385641865885. Valid Loss: 15.981958767080146.\n",
            "Epoch: 2120. Train Loss: 0.49342331217723884. Valid Loss: 15.98302634201205.\n",
            "Epoch: 2130. Train Loss: 0.49269078845530706. Valid Loss: 15.984113700111479.\n",
            "Epoch: 2140. Train Loss: 0.4919757715958482. Valid Loss: 15.985221454027853.\n",
            "Epoch: 2150. Train Loss: 0.4912777633780991. Valid Loss: 15.986342261414093.\n",
            "Epoch: 2160. Train Loss: 0.49059627780408466. Valid Loss: 15.98749116837605.\n",
            "Epoch: 2170. Train Loss: 0.48993084672482096. Valid Loss: 15.988652830385716.\n",
            "Epoch: 2180. Train Loss: 0.4892810133267372. Valid Loss: 15.989832972573529.\n",
            "Epoch: 2190. Train Loss: 0.4886463347054549. Valid Loss: 15.99103146687128.\n",
            "Epoch: 2200. Train Loss: 0.4880263810077154. Valid Loss: 15.992246184002255.\n",
            "Epoch: 2210. Train Loss: 0.48742073502916217. Valid Loss: 15.99347875049215.\n",
            "Epoch: 2220. Train Loss: 0.4868289918590932. Valid Loss: 15.994727353474303.\n",
            "Epoch: 2230. Train Loss: 0.4862507585359253. Valid Loss: 15.995992639597361.\n",
            "Epoch: 2240. Train Loss: 0.48568565371922573. Valid Loss: 15.997274018547834.\n",
            "Epoch: 2250. Train Loss: 0.4851333082811022. Valid Loss: 15.99857168505532.\n",
            "Epoch: 2260. Train Loss: 0.48459336060883895. Valid Loss: 15.999883537856302.\n",
            "Epoch: 2270. Train Loss: 0.4840654642355936. Valid Loss: 16.001212112037024.\n",
            "Epoch: 2280. Train Loss: 0.48354928096931554. Valid Loss: 16.002555240805307.\n",
            "Epoch: 2290. Train Loss: 0.48304448258423427. Valid Loss: 16.00391346809346.\n",
            "Epoch: 2300. Train Loss: 0.4825507508371741. Valid Loss: 16.005286399845158.\n",
            "Epoch: 2310. Train Loss: 0.4820677770038694. Valid Loss: 16.00667379584611.\n",
            "Epoch: 2320. Train Loss: 0.4815952615946584. Valid Loss: 16.00807560550439.\n",
            "Epoch: 2330. Train Loss: 0.48113292169009114. Valid Loss: 16.009492173830267.\n",
            "Epoch: 2340. Train Loss: 0.4806804543892724. Valid Loss: 16.010921707702423.\n",
            "Epoch: 2350. Train Loss: 0.4802376039426849. Valid Loss: 16.012365082965225.\n",
            "Epoch: 2360. Train Loss: 0.47980410282511354. Valid Loss: 16.01382246453574.\n",
            "Epoch: 2370. Train Loss: 0.4793796921203113. Valid Loss: 16.015293242061635.\n",
            "Epoch: 2380. Train Loss: 0.4789641223353194. Valid Loss: 16.016777570821535.\n",
            "Epoch: 2390. Train Loss: 0.47855715159483997. Valid Loss: 16.018274945667475.\n",
            "Epoch: 2400. Train Loss: 0.47815854530563545. Valid Loss: 16.019785552998272.\n",
            "Epoch: 2410. Train Loss: 0.47776807593764287. Valid Loss: 16.021309060718206.\n",
            "Epoch: 2420. Train Loss: 0.47738552283375973. Valid Loss: 16.0228454672303.\n",
            "Epoch: 2430. Train Loss: 0.4770106720119815. Valid Loss: 16.02439461491936.\n",
            "Epoch: 2440. Train Loss: 0.4766433159678053. Valid Loss: 16.025956407347717.\n",
            "Epoch: 2450. Train Loss: 0.4762832534814055. Valid Loss: 16.02753075773875.\n",
            "Epoch: 2460. Train Loss: 0.47593028943015553. Valid Loss: 16.029117555122884.\n",
            "Epoch: 2470. Train Loss: 0.4755842346062978. Valid Loss: 16.030716725546664.\n",
            "Epoch: 2480. Train Loss: 0.47524490553967313. Valid Loss: 16.032328178348216.\n",
            "Epoch: 2490. Train Loss: 0.47491212432540975. Valid Loss: 16.033951836440533.\n",
            "Epoch: 2500. Train Loss: 0.4745857184562804. Valid Loss: 16.03558762724214.\n",
            "Epoch: 2510. Train Loss: 0.47426552065951094. Valid Loss: 16.037235479927787.\n",
            "Epoch: 2520. Train Loss: 0.4739513687380351. Valid Loss: 16.038895329405584.\n",
            "Epoch: 2530. Train Loss: 0.4736431054161146. Valid Loss: 16.040567114693328.\n",
            "Epoch: 2540. Train Loss: 0.47334057818918257. Valid Loss: 16.042250778284245.\n",
            "Epoch: 2550. Train Loss: 0.4730436391778298. Valid Loss: 16.043946266470066.\n",
            "Epoch: 2560. Train Loss: 0.47275214498583223. Valid Loss: 16.045653529202276.\n",
            "Epoch: 2570. Train Loss: 0.4724659565621264. Valid Loss: 16.047372519834028.\n",
            "Epoch: 2580. Train Loss: 0.4721849390666415. Valid Loss: 16.049103194965152.\n",
            "Epoch: 2590. Train Loss: 0.4719089617398972. Valid Loss: 16.050845514316435.\n",
            "Epoch: 2600. Train Loss: 0.4716378977762797. Valid Loss: 16.05259944059297.\n",
            "Epoch: 2610. Train Loss: 0.47137162420090856. Valid Loss: 16.054364939344236.\n",
            "Epoch: 2620. Train Loss: 0.47111002175001165. Valid Loss: 16.056141978828354.\n",
            "Epoch: 2630. Train Loss: 0.4708529747547234. Valid Loss: 16.057930529880913.\n",
            "Epoch: 2640. Train Loss: 0.4706003710282262. Valid Loss: 16.059730565787437.\n",
            "Epoch: 2650. Train Loss: 0.4703521017561552. Valid Loss: 16.061542062157276.\n",
            "Epoch: 2660. Train Loss: 0.4701080613901883. Valid Loss: 16.06336499676127.\n",
            "Epoch: 2670. Train Loss: 0.46986814754474493. Valid Loss: 16.065199348293923.\n",
            "Epoch: 2680. Train Loss: 0.4696322608968169. Valid Loss: 16.0670450574115.\n",
            "Epoch: 2690. Train Loss: 0.46940030525701454. Valid Loss: 16.068900379512332.\n",
            "Epoch: 2700. Train Loss: 0.4691721869151509. Valid Loss: 16.07077312027855.\n",
            "Epoch: 2710. Train Loss: 0.4689478150223585. Valid Loss: 16.07264866800569.\n",
            "Epoch: 2720. Train Loss: 0.4687271025848036. Valid Loss: 16.074543172667617.\n",
            "Epoch: 2730. Train Loss: 0.4685099617028298. Valid Loss: 16.07644454428295.\n",
            "Epoch: 2740. Train Loss: 0.46829631206174804. Valid Loss: 16.078357756033657.\n",
            "Epoch: 2750. Train Loss: 0.46808607228090543. Valid Loss: 16.08028368746885.\n",
            "Epoch: 2760. Train Loss: 0.46787916427322185. Valid Loss: 16.08221978919562.\n",
            "Epoch: 2770. Train Loss: 0.46767551223322856. Valid Loss: 16.084167693655054.\n",
            "Epoch: 2780. Train Loss: 0.4674750425618931. Valid Loss: 16.08612680417344.\n",
            "Epoch: 2790. Train Loss: 0.46727768380273604. Valid Loss: 16.08809724812856.\n",
            "Epoch: 2800. Train Loss: 0.46708336670412626. Valid Loss: 16.09007865275267.\n",
            "Epoch: 2810. Train Loss: 0.46689202453587014. Valid Loss: 16.092072617171088.\n",
            "Epoch: 2820. Train Loss: 0.4667035891231135. Valid Loss: 16.094076120950284.\n",
            "Epoch: 2830. Train Loss: 0.46651799983494935. Valid Loss: 16.09609175084392.\n",
            "Epoch: 2840. Train Loss: 0.4663351939535271. Valid Loss: 16.098118842362755.\n",
            "Epoch: 2850. Train Loss: 0.4661551114171873. Valid Loss: 16.10015683972238.\n",
            "Epoch: 2860. Train Loss: 0.46597769395478345. Valid Loss: 16.102206439831686.\n",
            "Epoch: 2870. Train Loss: 0.46580288491620475. Valid Loss: 16.10426719321463.\n",
            "Epoch: 2880. Train Loss: 0.4656306292276517. Valid Loss: 16.106339262330867.\n",
            "Epoch: 2890. Train Loss: 0.4654608733563752. Valid Loss: 16.108422670454253.\n",
            "Epoch: 2900. Train Loss: 0.4652935652626116. Valid Loss: 16.11051734982037.\n",
            "Epoch: 2910. Train Loss: 0.46512865435171147. Valid Loss: 16.112623348029672.\n",
            "Epoch: 2920. Train Loss: 0.4649661034400814. Valid Loss: 16.114741109863175.\n",
            "Epoch: 2930. Train Loss: 0.4648058320676801. Valid Loss: 16.116869495456637.\n",
            "Epoch: 2940. Train Loss: 0.4646478195718781. Valid Loss: 16.119009242351666.\n",
            "Epoch: 2950. Train Loss: 0.46449201982673005. Valid Loss: 16.121160826315318.\n",
            "Epoch: 2960. Train Loss: 0.46433838236894404. Valid Loss: 16.123325136626736.\n",
            "Epoch: 2970. Train Loss: 0.4641868677532452. Valid Loss: 16.12549157729869.\n",
            "Epoch: 2980. Train Loss: 0.46403743031606687. Valid Loss: 16.127683979120782.\n",
            "Epoch: 2990. Train Loss: 0.46389003298504844. Valid Loss: 16.129877886389785.\n",
            "Epoch: 3000. Train Loss: 0.46374463527943593. Valid Loss: 16.132086169961884.\n"
          ]
        }
      ],
      "source": [
        "EPOCH = 3001\n",
        "trainLoss = []\n",
        "testLoss = []\n",
        "testEp = []\n",
        "for ep in tqdm(range(EPOCH)):\n",
        "    optimizer.zero_grad()\n",
        "    ratings_pred = torch.matmul(torch.cat((U, b), axis = 1), movies_tensor.T)\n",
        "    mask = ratings_train_tensor.bool()\n",
        "    nonzero_pred = ratings_pred.masked_select(mask)\n",
        "    nonzero_train = ratings_train_tensor.masked_select(mask)\n",
        "    loss = criterion(nonzero_pred, nonzero_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    trainLoss.append(loss.item())\n",
        "    if ep % 10 == 0:\n",
        "      testEp.append(ep)\n",
        "      mask = ratings_test_tensor.bool()\n",
        "      nonzero_pred = ratings_pred.masked_select(mask)\n",
        "      nonzero_test = ratings_test_tensor.masked_select(mask)\n",
        "      loss_test = criterion(nonzero_pred, nonzero_test)\n",
        "      testLoss.append(loss_test.item())\n",
        "      if minLoss > loss_test:\n",
        "        bestU = U\n",
        "        bestb = b\n",
        "        minLoss = loss_test\n",
        "      print(f'Epoch: {ep}. Train Loss: {loss}. Valid Loss: {loss_test}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "9qJ8Hpl1W-df",
        "outputId": "f1c59121-3acf-4abf-a2ea-c62c2efaee18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1f1de5b0190>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize = (16,9))\n",
        "numOfEpoch = 3001\n",
        "plt.plot(np.arange(0, numOfEpoch), trainLoss, label='Training Loss')\n",
        "plt.plot(testEp, testLoss, label='Validation Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "# plt.ylim((0.0,1.0))\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNMFbHYIo-mx"
      },
      "source": [
        "Now apply regularization weight_decay on U = 0.05 and lr = 0.005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1_ecNxLEozJx"
      },
      "outputs": [],
      "source": [
        "U = Variable(torch.randn(len_users, len_features, dtype = torch.float64), requires_grad=True)\n",
        "b = Variable(torch.randn(len_users, 1, dtype = torch.float64), requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8--tleoso1-W"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam([U], lr = 0.005, weight_decay = 0.05)\n",
        "optimizer.add_param_group({'params': b, \"lr\": 0.005, \"weight_decay\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ulla7mLJo4zu"
      },
      "outputs": [],
      "source": [
        "bestU = None\n",
        "bestb = None\n",
        "minLoss = 10e10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "027b77787c074d94b83239df7a7ec3cb",
            "9a873c70912248a984a221a03b25f560",
            "2e0e093cc21345e8bfd961f2f7ab4524",
            "cd445c9af4c74fccb88abde5baa1af76",
            "b53a596b9ed14c31b50241d4b681a649",
            "d53dcaf392044d84be757859817a3bfa",
            "6ee0f4ed5b104939a861a3365fa9fb05",
            "cea890e612aa471cb541e971aed3e353",
            "01e475555d6d42d89b5c87bc10af0a61",
            "f8c3530b4665428b9fd9fe79b1296fe6",
            "26dafdb3068d47ca82554868d3e6d7f7"
          ]
        },
        "id": "OOFtCxSro7Ji",
        "outputId": "9f351579-c3d6-4dbc-e199-ce15c69d7f04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "987be190b79845fd9e744f63971d0097",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3001 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0. Train Loss: 55.9389782447297. Valid Loss: 55.147542425539164.\n",
            "Epoch: 10. Train Loss: 51.16576388078184. Valid Loss: 50.76424633776617.\n",
            "Epoch: 20. Train Loss: 46.89062356850444. Valid Loss: 46.80002969246155.\n",
            "Epoch: 30. Train Loss: 43.105702403406646. Valid Loss: 43.253849195431016.\n",
            "Epoch: 40. Train Loss: 39.762101161333085. Valid Loss: 40.09216438898178.\n",
            "Epoch: 50. Train Loss: 36.7943421420201. Valid Loss: 37.263062551182216.\n",
            "Epoch: 60. Train Loss: 34.14371506174527. Valid Loss: 34.72015849898945.\n",
            "Epoch: 70. Train Loss: 31.76326618245502. Valid Loss: 32.42544171070686.\n",
            "Epoch: 80. Train Loss: 29.6161215018465. Valid Loss: 30.344087106954575.\n",
            "Epoch: 90. Train Loss: 27.6700173608674. Valid Loss: 28.446966860467956.\n",
            "Epoch: 100. Train Loss: 25.89867349219337. Valid Loss: 26.71109942035731.\n",
            "Epoch: 110. Train Loss: 24.28072142326709. Valid Loss: 25.11804714841044.\n",
            "Epoch: 120. Train Loss: 22.798566811160118. Valid Loss: 23.652150179779998.\n",
            "Epoch: 130. Train Loss: 21.437215661816577. Valid Loss: 22.29993195840985.\n",
            "Epoch: 140. Train Loss: 20.183904801379963. Valid Loss: 21.049837118124856.\n",
            "Epoch: 150. Train Loss: 19.02764439006523. Valid Loss: 19.891919899761206.\n",
            "Epoch: 160. Train Loss: 17.958927076279394. Valid Loss: 18.81756616881071.\n",
            "Epoch: 170. Train Loss: 16.969452720177564. Valid Loss: 17.819244779109244.\n",
            "Epoch: 180. Train Loss: 16.051928697981158. Valid Loss: 16.890307382444778.\n",
            "Epoch: 190. Train Loss: 15.199904603899737. Valid Loss: 16.024821572535384.\n",
            "Epoch: 200. Train Loss: 14.407637041183499. Valid Loss: 15.217482433085554.\n",
            "Epoch: 210. Train Loss: 13.669998184223937. Valid Loss: 14.463531192692287.\n",
            "Epoch: 220. Train Loss: 12.982392220263309. Valid Loss: 13.758677849153823.\n",
            "Epoch: 230. Train Loss: 12.340685672335367. Valid Loss: 13.099045131483438.\n",
            "Epoch: 240. Train Loss: 11.741151028195512. Valid Loss: 12.481120473995777.\n",
            "Epoch: 250. Train Loss: 11.180418731189924. Valid Loss: 11.901714201525024.\n",
            "Epoch: 260. Train Loss: 10.655435960293735. Valid Loss: 11.357923673203207.\n",
            "Epoch: 270. Train Loss: 10.163431416823983. Valid Loss: 10.847102523368273.\n",
            "Epoch: 280. Train Loss: 9.701884875294507. Valid Loss: 10.366834101927248.\n",
            "Epoch: 290. Train Loss: 9.268500800003837. Valid Loss: 9.914908409885046.\n",
            "Epoch: 300. Train Loss: 8.86118510425896. Valid Loss: 9.489301680479421.\n",
            "Epoch: 310. Train Loss: 8.47802486083557. Valid Loss: 9.088158440526497.\n",
            "Epoch: 320. Train Loss: 8.117270427530707. Valid Loss: 8.709775534956837.\n",
            "Epoch: 330. Train Loss: 7.777319612156319. Valid Loss: 8.352587893648288.\n",
            "Epoch: 340. Train Loss: 7.45670361144223. Valid Loss: 8.01515585765175.\n",
            "Epoch: 350. Train Loss: 7.154074492680663. Valid Loss: 7.6961538386261505.\n",
            "Epoch: 360. Train Loss: 6.8681940177881895. Valid Loss: 7.394360127776793.\n",
            "Epoch: 370. Train Loss: 6.5979236324292625. Valid Loss: 7.108647727990733.\n",
            "Epoch: 380. Train Loss: 6.342215480033821. Valid Loss: 6.837976089678768.\n",
            "Epoch: 390. Train Loss: 6.1001043173738685. Valid Loss: 6.581383644667443.\n",
            "Epoch: 400. Train Loss: 5.8707002283604846. Valid Loss: 6.337981053169417.\n",
            "Epoch: 410. Train Loss: 5.653182045555628. Valid Loss: 6.106945088242668.\n",
            "Epoch: 420. Train Loss: 5.446791401912263. Valid Loss: 5.887513090617308.\n",
            "Epoch: 430. Train Loss: 5.250827345651154. Valid Loss: 5.67897793570996.\n",
            "Epoch: 440. Train Loss: 5.064641459265789. Valid Loss: 5.480683461725174.\n",
            "Epoch: 450. Train Loss: 4.887633430895888. Valid Loss: 5.2920203128421734.\n",
            "Epoch: 460. Train Loss: 4.719247032323472. Valid Loss: 5.112422156573211.\n",
            "Epoch: 470. Train Loss: 4.558966463009365. Valid Loss: 4.941362238612425.\n",
            "Epoch: 480. Train Loss: 4.406313024103025. Valid Loss: 4.77835024230192.\n",
            "Epoch: 490. Train Loss: 4.260842090280977. Valid Loss: 4.622929423301236.\n",
            "Epoch: 500. Train Loss: 4.122140350686646. Valid Loss: 4.474673993059094.\n",
            "Epoch: 510. Train Loss: 3.989823293273812. Valid Loss: 4.33318672742695.\n",
            "Epoch: 520. Train Loss: 3.8635329095085136. Valid Loss: 4.198096779182754.\n",
            "Epoch: 530. Train Loss: 3.7429355987461594. Valid Loss: 4.069057675413002.\n",
            "Epoch: 540. Train Loss: 3.627720253695754. Valid Loss: 3.9457454826491944.\n",
            "Epoch: 550. Train Loss: 3.517596510242906. Valid Loss: 3.8278571243905826.\n",
            "Epoch: 560. Train Loss: 3.4122931465607897. Valid Loss: 3.7151088371944123.\n",
            "Epoch: 570. Train Loss: 3.3115566179164215. Valid Loss: 3.6072347528944104.\n",
            "Epoch: 580. Train Loss: 3.2151497148992534. Valid Loss: 3.503985595737494.\n",
            "Epoch: 590. Train Loss: 3.122850333979662. Valid Loss: 3.405127484324423.\n",
            "Epoch: 600. Train Loss: 3.0344503503620768. Valid Loss: 3.310440829216483.\n",
            "Epoch: 610. Train Loss: 2.94975458404563. Valid Loss: 3.2197193179417036.\n",
            "Epoch: 620. Train Loss: 2.868579850856846. Valid Loss: 3.1327689799122984.\n",
            "Epoch: 630. Train Loss: 2.7907540909848856. Valid Loss: 3.0494073244610846.\n",
            "Epoch: 640. Train Loss: 2.716115568239742. Valid Loss: 2.9694625458281734.\n",
            "Epoch: 650. Train Loss: 2.6445121338760096. Valid Loss: 2.8927727894888977.\n",
            "Epoch: 660. Train Loss: 2.575800549386729. Valid Loss: 2.819185474717177.\n",
            "Epoch: 670. Train Loss: 2.509845863179744. Valid Loss: 2.7485566687318803.\n",
            "Epoch: 680. Train Loss: 2.44652083650875. Valid Loss: 2.6807505081830714.\n",
            "Epoch: 690. Train Loss: 2.385705414447675. Valid Loss: 2.6156386641051292.\n",
            "Epoch: 700. Train Loss: 2.327286238074654. Valid Loss: 2.553099846799169.\n",
            "Epoch: 710. Train Loss: 2.2711561943744956. Valid Loss: 2.4930193474115208.\n",
            "Epoch: 720. Train Loss: 2.2172140006796384. Valid Loss: 2.4352886132516716.\n",
            "Epoch: 730. Train Loss: 2.1653638207522126. Valid Loss: 2.3798048541448504.\n",
            "Epoch: 740. Train Loss: 2.1155149098666644. Valid Loss: 2.3264706773437687.\n",
            "Epoch: 750. Train Loss: 2.0675812864858987. Valid Loss: 2.2751937487332454.\n",
            "Epoch: 760. Train Loss: 2.021481428336227. Valid Loss: 2.225886478252305.\n",
            "Epoch: 770. Train Loss: 1.9771379908795146. Valid Loss: 2.178465727632653.\n",
            "Epoch: 780. Train Loss: 1.9344775463565427. Valid Loss: 2.1328525387116772.\n",
            "Epoch: 790. Train Loss: 1.893430341735378. Valid Loss: 2.0889718807236135.\n",
            "Epoch: 800. Train Loss: 1.8539300740438405. Valid Loss: 2.046752415105503.\n",
            "Epoch: 810. Train Loss: 1.8159136816973305. Valid Loss: 2.0061262764761136.\n",
            "Epoch: 820. Train Loss: 1.7793211505534914. Valid Loss: 1.9670288685571005.\n",
            "Epoch: 830. Train Loss: 1.7440953335344986. Valid Loss: 1.9293986739071958.\n",
            "Epoch: 840. Train Loss: 1.7101817827572137. Valid Loss: 1.8931770764330462.\n",
            "Epoch: 850. Train Loss: 1.6775285932018416. Valid Loss: 1.8583081957250875.\n",
            "Epoch: 860. Train Loss: 1.6460862570319954. Valid Loss: 1.82473873234435.\n",
            "Epoch: 870. Train Loss: 1.6158075277538448. Valid Loss: 1.792417823256867.\n",
            "Epoch: 880. Train Loss: 1.586647293470087. Valid Loss: 1.7612969066770594.\n",
            "Epoch: 890. Train Loss: 1.5585624585463704. Valid Loss: 1.731329595640549.\n",
            "Epoch: 900. Train Loss: 1.531511833064147. Valid Loss: 1.702471559680863.\n",
            "Epoch: 910. Train Loss: 1.505456029485199. Valid Loss: 1.6746804140338256.\n",
            "Epoch: 920. Train Loss: 1.4803573659998055. Valid Loss: 1.647915615838537.\n",
            "Epoch: 930. Train Loss: 1.4561797760730444. Valid Loss: 1.622138366845072.\n",
            "Epoch: 940. Train Loss: 1.4328887237425267. Valid Loss: 1.59731152217673.\n",
            "Epoch: 950. Train Loss: 1.4104511242562197. Valid Loss: 1.5733995047291789.\n",
            "Epoch: 960. Train Loss: 1.388835269671313. Valid Loss: 1.5503682248204083.\n",
            "Epoch: 970. Train Loss: 1.368010759064561. Valid Loss: 1.5281850047343277.\n",
            "Epoch: 980. Train Loss: 1.3479484330314864. Valid Loss: 1.506818507827375.\n",
            "Epoch: 990. Train Loss: 1.328620312176485. Valid Loss: 1.4862386718917933.\n",
            "Epoch: 1000. Train Loss: 1.309999539318443. Valid Loss: 1.466416646491567.\n",
            "Epoch: 1010. Train Loss: 1.292060325157154. Valid Loss: 1.4473247340075142.\n",
            "Epoch: 1020. Train Loss: 1.274777897164807. Valid Loss: 1.4289363341468742.\n",
            "Epoch: 1030. Train Loss: 1.2581284514842146. Valid Loss: 1.411225891690103.\n",
            "Epoch: 1040. Train Loss: 1.2420891076314697. Valid Loss: 1.3941688472635618.\n",
            "Epoch: 1050. Train Loss: 1.226637865815431. Valid Loss: 1.3777415909415354.\n",
            "Epoch: 1060. Train Loss: 1.2117535666999881. Valid Loss: 1.3619214184946329.\n",
            "Epoch: 1070. Train Loss: 1.1974158534475559. Valid Loss: 1.3466864901142033.\n",
            "Epoch: 1080. Train Loss: 1.1836051358937576. Valid Loss: 1.3320157914540263.\n",
            "Epoch: 1090. Train Loss: 1.1703025567138956. Valid Loss: 1.3178890968413304.\n",
            "Epoch: 1100. Train Loss: 1.1574899594516372. Valid Loss: 1.3042869345191637.\n",
            "Epoch: 1110. Train Loss: 1.145149858289425. Valid Loss: 1.2911905537914246.\n",
            "Epoch: 1120. Train Loss: 1.133265409448541. Valid Loss: 1.2785818939504483.\n",
            "Epoch: 1130. Train Loss: 1.1218203841145304. Valid Loss: 1.2664435548750612.\n",
            "Epoch: 1140. Train Loss: 1.110799142790922. Valid Loss: 1.2547587691944373.\n",
            "Epoch: 1150. Train Loss: 1.100186610990872. Valid Loss: 1.2435113759200265.\n",
            "Epoch: 1160. Train Loss: 1.0899682561825672. Valid Loss: 1.2326857954542731.\n",
            "Epoch: 1170. Train Loss: 1.080130065910003. Valid Loss: 1.2222670058908478.\n",
            "Epoch: 1180. Train Loss: 1.0706585270162907. Valid Loss: 1.2122405205268134.\n",
            "Epoch: 1190. Train Loss: 1.061540605911806. Valid Loss: 1.2025923665167724.\n",
            "Epoch: 1200. Train Loss: 1.0527637305849007. Valid Loss: 1.1933090649321527.\n",
            "Epoch: 1210. Train Loss: 1.0443158484876702. Valid Loss: 1.1843776449528112.\n",
            "Epoch: 1220. Train Loss: 1.0361841869723603. Valid Loss: 1.1757851285838552.\n",
            "Epoch: 1230. Train Loss: 1.0283606805602197. Valid Loss: 1.1675206757478391.\n",
            "Epoch: 1240. Train Loss: 1.0208305994381002. Valid Loss: 1.159570567422603.\n",
            "Epoch: 1250. Train Loss: 1.0135850035211427. Valid Loss: 1.1519256402241367.\n",
            "Epoch: 1260. Train Loss: 1.0066141888016413. Valid Loss: 1.1445738038716513.\n",
            "Epoch: 1270. Train Loss: 0.9999075642672405. Valid Loss: 1.1375047797063922.\n",
            "Epoch: 1280. Train Loss: 0.9934563375084866. Valid Loss: 1.1307068905763291.\n",
            "Epoch: 1290. Train Loss: 0.9872509104416378. Valid Loss: 1.124173140242991.\n",
            "Epoch: 1300. Train Loss: 0.9812824796068098. Valid Loss: 1.1178950166484236.\n",
            "Epoch: 1310. Train Loss: 0.9755426793117812. Valid Loss: 1.1118585502136344.\n",
            "Epoch: 1320. Train Loss: 0.9700236399187134. Valid Loss: 1.106057757979721.\n",
            "Epoch: 1330. Train Loss: 0.9647167594345818. Valid Loss: 1.1004836371437936.\n",
            "Epoch: 1340. Train Loss: 0.9596146880659421. Valid Loss: 1.0951283203129045.\n",
            "Epoch: 1350. Train Loss: 0.9547100527236505. Valid Loss: 1.089984851605733.\n",
            "Epoch: 1360. Train Loss: 0.9499950671953273. Valid Loss: 1.085044148474543.\n",
            "Epoch: 1370. Train Loss: 0.9454638872099508. Valid Loss: 1.0802978222771535.\n",
            "Epoch: 1380. Train Loss: 0.941109272994675. Valid Loss: 1.0757408820177767.\n",
            "Epoch: 1390. Train Loss: 0.9369248149026292. Valid Loss: 1.0713653470563376.\n",
            "Epoch: 1400. Train Loss: 0.9329045562016837. Valid Loss: 1.067162439532862.\n",
            "Epoch: 1410. Train Loss: 0.9290419166342383. Valid Loss: 1.0631328204310893.\n",
            "Epoch: 1420. Train Loss: 0.9253318204691636. Valid Loss: 1.059261426323796.\n",
            "Epoch: 1430. Train Loss: 0.9217678720943805. Valid Loss: 1.0555481624366756.\n",
            "Epoch: 1440. Train Loss: 0.9183454940513285. Valid Loss: 1.0519846652563347.\n",
            "Epoch: 1450. Train Loss: 0.9150590263407142. Valid Loss: 1.048565428159589.\n",
            "Epoch: 1460. Train Loss: 0.91190326614889. Valid Loss: 1.04528602842996.\n",
            "Epoch: 1470. Train Loss: 0.9088738279910693. Valid Loss: 1.0421400072071145.\n",
            "Epoch: 1480. Train Loss: 0.905965332002761. Valid Loss: 1.0391240538068964.\n",
            "Epoch: 1490. Train Loss: 0.903174301860821. Valid Loss: 1.0362320855109464.\n",
            "Epoch: 1500. Train Loss: 0.9004956500628898. Valid Loss: 1.0334595914390758.\n",
            "Epoch: 1510. Train Loss: 0.8979249461894488. Valid Loss: 1.0308019279060205.\n",
            "Epoch: 1520. Train Loss: 0.8954584378924005. Valid Loss: 1.0282545237142593.\n",
            "Epoch: 1530. Train Loss: 0.893092037421134. Valid Loss: 1.0258135870819671.\n",
            "Epoch: 1540. Train Loss: 0.8908220675671963. Valid Loss: 1.0234741842329078.\n",
            "Epoch: 1550. Train Loss: 0.8886454553989227. Valid Loss: 1.0212345889693517.\n",
            "Epoch: 1560. Train Loss: 0.8865583035156882. Valid Loss: 1.019089879795931.\n",
            "Epoch: 1570. Train Loss: 0.8845560501527291. Valid Loss: 1.017034537661708.\n",
            "Epoch: 1580. Train Loss: 0.8826375531351304. Valid Loss: 1.0150650858538994.\n",
            "Epoch: 1590. Train Loss: 0.8807970000414796. Valid Loss: 1.0131851829173937.\n",
            "Epoch: 1600. Train Loss: 0.8790349533629984. Valid Loss: 1.0113785825779242.\n",
            "Epoch: 1610. Train Loss: 0.8773446514894474. Valid Loss: 1.0096547756768561.\n",
            "Epoch: 1620. Train Loss: 0.8757238937307146. Valid Loss: 1.0080070005567137.\n",
            "Epoch: 1630. Train Loss: 0.8741731877000516. Valid Loss: 1.0064253139469685.\n",
            "Epoch: 1640. Train Loss: 0.8726854393446599. Valid Loss: 1.004912928482105.\n",
            "Epoch: 1650. Train Loss: 0.8712618908699434. Valid Loss: 1.0034696035419828.\n",
            "Epoch: 1660. Train Loss: 0.8698981701617124. Valid Loss: 1.0020886682473924.\n",
            "Epoch: 1670. Train Loss: 0.8685922994661893. Valid Loss: 1.000768399952494.\n",
            "Epoch: 1680. Train Loss: 0.8673417979037849. Valid Loss: 0.9995052050985441.\n",
            "Epoch: 1690. Train Loss: 0.86614469965249. Valid Loss: 0.9982991678003847.\n",
            "Epoch: 1700. Train Loss: 0.8649993082549008. Valid Loss: 0.9971465463856473.\n",
            "Epoch: 1710. Train Loss: 0.8639020038428471. Valid Loss: 0.9960448688637542.\n",
            "Epoch: 1720. Train Loss: 0.8628531027436812. Valid Loss: 0.9949964580537702.\n",
            "Epoch: 1730. Train Loss: 0.8618477706635388. Valid Loss: 0.993988572746614.\n",
            "Epoch: 1740. Train Loss: 0.860887431996545. Valid Loss: 0.9930301288863451.\n",
            "Epoch: 1750. Train Loss: 0.8599687390023691. Valid Loss: 0.9921133890731328.\n",
            "Epoch: 1760. Train Loss: 0.8590895905647313. Valid Loss: 0.991239892822843.\n",
            "Epoch: 1770. Train Loss: 0.8582491407387527. Valid Loss: 0.9904061060711052.\n",
            "Epoch: 1780. Train Loss: 0.8574455578871888. Valid Loss: 0.9896109466055507.\n",
            "Epoch: 1790. Train Loss: 0.8566769692595606. Valid Loss: 0.9888535087799694.\n",
            "Epoch: 1800. Train Loss: 0.8559430281845444. Valid Loss: 0.9881277725403197.\n",
            "Epoch: 1810. Train Loss: 0.855240806696927. Valid Loss: 0.9874392183419861.\n",
            "Epoch: 1820. Train Loss: 0.8545706650142256. Valid Loss: 0.9867808823337291.\n",
            "Epoch: 1830. Train Loss: 0.8539289674775916. Valid Loss: 0.9861546505071445.\n",
            "Epoch: 1840. Train Loss: 0.8533177376400042. Valid Loss: 0.9855565100004499.\n",
            "Epoch: 1850. Train Loss: 0.852732390775714. Valid Loss: 0.9849879147442187.\n",
            "Epoch: 1860. Train Loss: 0.8521740319085224. Valid Loss: 0.9844471904997605.\n",
            "Epoch: 1870. Train Loss: 0.8516406757253929. Valid Loss: 0.983930489112808.\n",
            "Epoch: 1880. Train Loss: 0.8511316489507013. Valid Loss: 0.9834399738291459.\n",
            "Epoch: 1890. Train Loss: 0.850645722171872. Valid Loss: 0.9829727035940057.\n",
            "Epoch: 1900. Train Loss: 0.850181625335974. Valid Loss: 0.9825277526444995.\n",
            "Epoch: 1910. Train Loss: 0.8497385008598399. Valid Loss: 0.982106195580808.\n",
            "Epoch: 1920. Train Loss: 0.8493168148505073. Valid Loss: 0.9817032442994987.\n",
            "Epoch: 1930. Train Loss: 0.8489133845138687. Valid Loss: 0.9813190833488916.\n",
            "Epoch: 1940. Train Loss: 0.848529931141055. Valid Loss: 0.9809563999901785.\n",
            "Epoch: 1950. Train Loss: 0.8481623688076878. Valid Loss: 0.9806102666261118.\n",
            "Epoch: 1960. Train Loss: 0.8478130656311116. Valid Loss: 0.9802814357886538.\n",
            "Epoch: 1970. Train Loss: 0.8474796629058964. Valid Loss: 0.9799696769212835.\n",
            "Epoch: 1980. Train Loss: 0.8471620929390872. Valid Loss: 0.9796739323833077.\n",
            "Epoch: 1990. Train Loss: 0.8468591060847304. Valid Loss: 0.9793935053843915.\n",
            "Epoch: 2000. Train Loss: 0.8465702473862264. Valid Loss: 0.9791265549257009.\n",
            "Epoch: 2010. Train Loss: 0.8462954958392968. Valid Loss: 0.9788733196491427.\n",
            "Epoch: 2020. Train Loss: 0.8460336171617805. Valid Loss: 0.9786338444488414.\n",
            "Epoch: 2030. Train Loss: 0.8457840955395401. Valid Loss: 0.9784062445278306.\n",
            "Epoch: 2040. Train Loss: 0.8455467681794595. Valid Loss: 0.9781927261732192.\n",
            "Epoch: 2050. Train Loss: 0.8453203806437917. Valid Loss: 0.9779884192921445.\n",
            "Epoch: 2060. Train Loss: 0.8451044930096758. Valid Loss: 0.977790948390351.\n",
            "Epoch: 2070. Train Loss: 0.8448999754789593. Valid Loss: 0.9776107045622398.\n",
            "Epoch: 2080. Train Loss: 0.8447050454469769. Valid Loss: 0.9774374727186199.\n",
            "Epoch: 2090. Train Loss: 0.8445186957803918. Valid Loss: 0.9772706363845447.\n",
            "Epoch: 2100. Train Loss: 0.8443414099989175. Valid Loss: 0.977116362514116.\n",
            "Epoch: 2110. Train Loss: 0.8441738657541745. Valid Loss: 0.9769685846969872.\n",
            "Epoch: 2120. Train Loss: 0.8440144431516302. Valid Loss: 0.9768305211407556.\n",
            "Epoch: 2130. Train Loss: 0.8438614986801046. Valid Loss: 0.9767003108571555.\n",
            "Epoch: 2140. Train Loss: 0.8437180556921041. Valid Loss: 0.9765784898691726.\n",
            "Epoch: 2150. Train Loss: 0.84357967475476. Valid Loss: 0.9764576231891721.\n",
            "Epoch: 2160. Train Loss: 0.8434492748580541. Valid Loss: 0.9763499651835115.\n",
            "Epoch: 2170. Train Loss: 0.8433249990341635. Valid Loss: 0.9762452471367368.\n",
            "Epoch: 2180. Train Loss: 0.8432075427863015. Valid Loss: 0.976145744336845.\n",
            "Epoch: 2190. Train Loss: 0.8430949521788462. Valid Loss: 0.976056325832704.\n",
            "Epoch: 2200. Train Loss: 0.8429903655903438. Valid Loss: 0.9759665009269026.\n",
            "Epoch: 2210. Train Loss: 0.8428882568990106. Valid Loss: 0.9758861749461929.\n",
            "Epoch: 2220. Train Loss: 0.8427916121133736. Valid Loss: 0.9758114311535018.\n",
            "Epoch: 2230. Train Loss: 0.8427007803967093. Valid Loss: 0.975735361271795.\n",
            "Epoch: 2240. Train Loss: 0.8426143523688773. Valid Loss: 0.9756688446027535.\n",
            "Epoch: 2250. Train Loss: 0.8425317749543113. Valid Loss: 0.9756059228775339.\n",
            "Epoch: 2260. Train Loss: 0.8424541977182423. Valid Loss: 0.975544826338574.\n",
            "Epoch: 2270. Train Loss: 0.8423791465708497. Valid Loss: 0.9754887717013382.\n",
            "Epoch: 2280. Train Loss: 0.8423105970987903. Valid Loss: 0.9754381601131803.\n",
            "Epoch: 2290. Train Loss: 0.8422431624453598. Valid Loss: 0.9753875527348126.\n",
            "Epoch: 2300. Train Loss: 0.8421807435174009. Valid Loss: 0.9753413908929177.\n",
            "Epoch: 2310. Train Loss: 0.8421215636034131. Valid Loss: 0.9752987335043213.\n",
            "Epoch: 2320. Train Loss: 0.8420650299591105. Valid Loss: 0.9752583825907443.\n",
            "Epoch: 2330. Train Loss: 0.8420105911252873. Valid Loss: 0.975219935346379.\n",
            "Epoch: 2340. Train Loss: 0.8419604574546153. Valid Loss: 0.9751877980639072.\n",
            "Epoch: 2350. Train Loss: 0.8419115076900793. Valid Loss: 0.9751524884012407.\n",
            "Epoch: 2360. Train Loss: 0.8418670245242508. Valid Loss: 0.9751238537679772.\n",
            "Epoch: 2370. Train Loss: 0.8418245183470917. Valid Loss: 0.975095482904132.\n",
            "Epoch: 2380. Train Loss: 0.8417822046678686. Valid Loss: 0.9750690460814398.\n",
            "Epoch: 2390. Train Loss: 0.8417430930475428. Valid Loss: 0.9750447311083421.\n",
            "Epoch: 2400. Train Loss: 0.8417072294998444. Valid Loss: 0.9750225667798084.\n",
            "Epoch: 2410. Train Loss: 0.841672115415726. Valid Loss: 0.9750022114998609.\n",
            "Epoch: 2420. Train Loss: 0.8416394215574332. Valid Loss: 0.9749833276300814.\n",
            "Epoch: 2430. Train Loss: 0.8416082864714612. Valid Loss: 0.9749654194145382.\n",
            "Epoch: 2440. Train Loss: 0.8415789844735998. Valid Loss: 0.9749486456865056.\n",
            "Epoch: 2450. Train Loss: 0.8415517507120507. Valid Loss: 0.974935873650105.\n",
            "Epoch: 2460. Train Loss: 0.8415250399307995. Valid Loss: 0.9749202378515257.\n",
            "Epoch: 2470. Train Loss: 0.8415007617767372. Valid Loss: 0.9749092611990522.\n",
            "Epoch: 2480. Train Loss: 0.8414768387131607. Valid Loss: 0.9748980860960382.\n",
            "Epoch: 2490. Train Loss: 0.8414549535530095. Valid Loss: 0.9748884799548784.\n",
            "Epoch: 2500. Train Loss: 0.8414338871496096. Valid Loss: 0.9748786184665813.\n",
            "Epoch: 2510. Train Loss: 0.8414149253963544. Valid Loss: 0.9748713399061772.\n",
            "Epoch: 2520. Train Loss: 0.8413958413048788. Valid Loss: 0.974863812207923.\n",
            "Epoch: 2530. Train Loss: 0.8413779396672671. Valid Loss: 0.9748571187453708.\n",
            "Epoch: 2540. Train Loss: 0.8413618391282067. Valid Loss: 0.9748494208287345.\n",
            "Epoch: 2550. Train Loss: 0.8413458789141093. Valid Loss: 0.9748453198012387.\n",
            "Epoch: 2560. Train Loss: 0.8413310627004218. Valid Loss: 0.9748422749748307.\n",
            "Epoch: 2570. Train Loss: 0.8413173602416923. Valid Loss: 0.9748370593649579.\n",
            "Epoch: 2580. Train Loss: 0.8413045915121011. Valid Loss: 0.9748357632676243.\n",
            "Epoch: 2590. Train Loss: 0.8412918233730088. Valid Loss: 0.9748326704345741.\n",
            "Epoch: 2600. Train Loss: 0.8412805562916263. Valid Loss: 0.9748321098315359.\n",
            "Epoch: 2610. Train Loss: 0.8412692739580855. Valid Loss: 0.9748294500116793.\n",
            "Epoch: 2620. Train Loss: 0.8412588793326751. Valid Loss: 0.974827685361632.\n",
            "Epoch: 2630. Train Loss: 0.8412487277406017. Valid Loss: 0.9748260093680041.\n",
            "Epoch: 2640. Train Loss: 0.8412397741213761. Valid Loss: 0.9748268580869945.\n",
            "Epoch: 2650. Train Loss: 0.8412328850647359. Valid Loss: 0.9748259219924171.\n",
            "Epoch: 2660. Train Loss: 0.8412243729301869. Valid Loss: 0.9748255681922036.\n",
            "Epoch: 2670. Train Loss: 0.841215598802305. Valid Loss: 0.9748291142185084.\n",
            "Epoch: 2680. Train Loss: 0.8412079806490098. Valid Loss: 0.9748280626645704.\n",
            "Epoch: 2690. Train Loss: 0.8412015274945704. Valid Loss: 0.9748289464446199.\n",
            "Epoch: 2700. Train Loss: 0.8411958628457133. Valid Loss: 0.97483232862137.\n",
            "Epoch: 2710. Train Loss: 0.8411888236388536. Valid Loss: 0.9748312791844308.\n",
            "Epoch: 2720. Train Loss: 0.8411841113843899. Valid Loss: 0.9748353260168604.\n",
            "Epoch: 2730. Train Loss: 0.8411782444929461. Valid Loss: 0.9748321707786771.\n",
            "Epoch: 2740. Train Loss: 0.8411733873235437. Valid Loss: 0.9748360852455464.\n",
            "Epoch: 2750. Train Loss: 0.8411684486307855. Valid Loss: 0.9748408225895361.\n",
            "Epoch: 2760. Train Loss: 0.8411633472331602. Valid Loss: 0.9748400590114904.\n",
            "Epoch: 2770. Train Loss: 0.8411604543000792. Valid Loss: 0.9748448003223584.\n",
            "Epoch: 2780. Train Loss: 0.8411563795824366. Valid Loss: 0.9748468781641424.\n",
            "Epoch: 2790. Train Loss: 0.841152270652638. Valid Loss: 0.9748502543847272.\n",
            "Epoch: 2800. Train Loss: 0.8411486738456057. Valid Loss: 0.9748509248620832.\n",
            "Epoch: 2810. Train Loss: 0.8411457851381765. Valid Loss: 0.974854952894873.\n",
            "Epoch: 2820. Train Loss: 0.8411427375442304. Valid Loss: 0.9748567739326975.\n",
            "Epoch: 2830. Train Loss: 0.8411397092728918. Valid Loss: 0.9748605468002107.\n",
            "Epoch: 2840. Train Loss: 0.8411372403166155. Valid Loss: 0.974863561125982.\n",
            "Epoch: 2850. Train Loss: 0.8411351034641504. Valid Loss: 0.974865938895691.\n",
            "Epoch: 2860. Train Loss: 0.8411324907373721. Valid Loss: 0.974868244695509.\n",
            "Epoch: 2870. Train Loss: 0.8411320575521221. Valid Loss: 0.9748725316110144.\n",
            "Epoch: 2880. Train Loss: 0.8411285329666875. Valid Loss: 0.9748724206420296.\n",
            "Epoch: 2890. Train Loss: 0.8411266793349186. Valid Loss: 0.9748787553852852.\n",
            "Epoch: 2900. Train Loss: 0.8411242518105827. Valid Loss: 0.9748803461683523.\n",
            "Epoch: 2910. Train Loss: 0.841123418046893. Valid Loss: 0.9748868661900919.\n",
            "Epoch: 2920. Train Loss: 0.8411213824993556. Valid Loss: 0.9748838929928181.\n",
            "Epoch: 2930. Train Loss: 0.841120501874219. Valid Loss: 0.9748927314577475.\n",
            "Epoch: 2940. Train Loss: 0.8411186123334017. Valid Loss: 0.9748918922153896.\n",
            "Epoch: 2950. Train Loss: 0.841117807102175. Valid Loss: 0.9748955251525036.\n",
            "Epoch: 2960. Train Loss: 0.8411164093024701. Valid Loss: 0.9748978964684433.\n",
            "Epoch: 2970. Train Loss: 0.8411145614219754. Valid Loss: 0.9749011254162573.\n",
            "Epoch: 2980. Train Loss: 0.8411136577585431. Valid Loss: 0.9749056034183182.\n",
            "Epoch: 2990. Train Loss: 0.8411132528016062. Valid Loss: 0.9749069474520615.\n",
            "Epoch: 3000. Train Loss: 0.841112364909852. Valid Loss: 0.974908458449985.\n"
          ]
        }
      ],
      "source": [
        "EPOCH = 3001\n",
        "trainLoss = []\n",
        "testLoss = []\n",
        "testEp = []\n",
        "for ep in tqdm(range(EPOCH)):\n",
        "    optimizer.zero_grad()\n",
        "    ratings_pred = torch.matmul(torch.cat((U, b), axis = 1), movies_tensor.T)\n",
        "    mask = ratings_train_tensor.bool()\n",
        "    nonzero_pred = ratings_pred.masked_select(mask)\n",
        "    nonzero_train = ratings_train_tensor.masked_select(mask)\n",
        "    loss = criterion(nonzero_pred, nonzero_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    trainLoss.append(loss.item())\n",
        "    if ep % 10 == 0:\n",
        "      testEp.append(ep)\n",
        "      mask = ratings_test_tensor.bool()\n",
        "      nonzero_pred = ratings_pred.masked_select(mask)\n",
        "      nonzero_test = ratings_test_tensor.masked_select(mask)\n",
        "      loss_test = criterion(nonzero_pred, nonzero_test)\n",
        "      testLoss.append(loss_test.item())\n",
        "      if minLoss > loss_test:\n",
        "        bestU = U\n",
        "        bestb = b\n",
        "        minLoss = loss_test\n",
        "      print(f'Epoch: {ep}. Train Loss: {loss}. Valid Loss: {loss_test}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "y9_gBbkMo9nz",
        "outputId": "1e684500-0c9b-4852-dcc2-4b8913d7b8b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1f1dc364d30>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize = (16,9))\n",
        "numOfEpoch = 3001\n",
        "plt.plot(np.arange(0, numOfEpoch), trainLoss, label='Training Loss')\n",
        "plt.plot(testEp, testLoss, label='Validation Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "# plt.ylim((0.0,1.0))\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ_aJpD-bWB7"
      },
      "source": [
        "Take minLoss and bestU, bestb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yol-SnS8ZyWZ",
        "outputId": "f1929884-6b1c-4d99-c1fb-21f813915e81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9748, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG3lzfAmZ6oW",
        "outputId": "a63601fc-f856-4a29-88c6-cad539af63ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-4.6181e-05,  9.1841e-05,  5.4503e-04,  ..., -2.8541e-11,\n",
              "         -8.9279e-12, -8.4979e-12],\n",
              "        [-1.1335e-03, -1.2419e-02,  5.2176e-03,  ...,  2.4515e-05,\n",
              "          7.1601e-03, -2.4875e-05],\n",
              "        [ 1.6921e-03, -1.9156e-03, -1.5166e-03,  ...,  4.0575e-03,\n",
              "         -2.9814e-03, -3.4898e-05],\n",
              "        ...,\n",
              "        [ 2.5991e-03, -1.2845e-03,  1.1771e-03,  ...,  3.7455e-03,\n",
              "         -4.3664e-12, -3.5235e-12],\n",
              "        [ 7.7401e-04, -2.1844e-03,  1.0291e-04,  ...,  3.0103e-03,\n",
              "          1.1067e-02, -4.8461e-10],\n",
              "        [-7.9729e-04, -1.4242e-03, -1.8596e-04,  ...,  4.8769e-03,\n",
              "         -3.6594e-03, -8.5257e-03]], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bestU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ATtO1DT3bTcU"
      },
      "outputs": [],
      "source": [
        "bestU.detach().numpy().tofile(\"ModelStorage/U.txt\")\n",
        "bestb.detach().numpy().tofile(\"ModelStorage/b.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LmyIu1RGdcs0"
      },
      "outputs": [],
      "source": [
        "with open(\"ModelStorage/indexToId.txt\", \"w+\") as file:\n",
        "  file.write(str(indexToId))\n",
        "with open(\"ModelStorage/idToIndex.txt\", \"w+\") as file:\n",
        "  file.write(str(idToIndex))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Content_Based_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01e475555d6d42d89b5c87bc10af0a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027b77787c074d94b83239df7a7ec3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a873c70912248a984a221a03b25f560",
              "IPY_MODEL_2e0e093cc21345e8bfd961f2f7ab4524",
              "IPY_MODEL_cd445c9af4c74fccb88abde5baa1af76"
            ],
            "layout": "IPY_MODEL_b53a596b9ed14c31b50241d4b681a649"
          }
        },
        "10bf11ffa98b4e3db983996a1c2312f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e09e24747c64b2ba9365f0a9a5824ea",
            "max": 3001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dda87b7df3849b59c4dbbcf69be4435",
            "value": 3001
          }
        },
        "26dafdb3068d47ca82554868d3e6d7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2754049777b64696a792343cddb4183f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4a934113a04c1a90263772a5f344a5",
            "placeholder": "​",
            "style": "IPY_MODEL_c290ae7d67cc4edcb909f16b6936107f",
            "value": " 3001/3001 [02:25&lt;00:00, 24.38it/s]"
          }
        },
        "2e0e093cc21345e8bfd961f2f7ab4524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea890e612aa471cb541e971aed3e353",
            "max": 3001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01e475555d6d42d89b5c87bc10af0a61",
            "value": 3001
          }
        },
        "3c4a934113a04c1a90263772a5f344a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dda87b7df3849b59c4dbbcf69be4435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40e878e6253c4f4b8df8dcf9a6154270": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e599ed8b209145819b374acc5632453e",
              "IPY_MODEL_10bf11ffa98b4e3db983996a1c2312f5",
              "IPY_MODEL_2754049777b64696a792343cddb4183f"
            ],
            "layout": "IPY_MODEL_e20c010704724632ae65fce3bee1227e"
          }
        },
        "6ee0f4ed5b104939a861a3365fa9fb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e09e24747c64b2ba9365f0a9a5824ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a873c70912248a984a221a03b25f560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d53dcaf392044d84be757859817a3bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_6ee0f4ed5b104939a861a3365fa9fb05",
            "value": "100%"
          }
        },
        "a87f5641a4cc45e4b9680c4f39f10adb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53a596b9ed14c31b50241d4b681a649": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c290ae7d67cc4edcb909f16b6936107f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd445c9af4c74fccb88abde5baa1af76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c3530b4665428b9fd9fe79b1296fe6",
            "placeholder": "​",
            "style": "IPY_MODEL_26dafdb3068d47ca82554868d3e6d7f7",
            "value": " 3001/3001 [02:07&lt;00:00, 24.25it/s]"
          }
        },
        "cea890e612aa471cb541e971aed3e353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53dcaf392044d84be757859817a3bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20c010704724632ae65fce3bee1227e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e599ed8b209145819b374acc5632453e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87f5641a4cc45e4b9680c4f39f10adb",
            "placeholder": "​",
            "style": "IPY_MODEL_f7e37addf6634720951ecad54ff229b5",
            "value": "100%"
          }
        },
        "f7e37addf6634720951ecad54ff229b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c3530b4665428b9fd9fe79b1296fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
